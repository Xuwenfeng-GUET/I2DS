{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "path_train = \"F:/数据集/UNSW_NB15/UNSW_NB15_CSV/UNSW_NB15_training-set.csv\"\n",
    "path_test = \"F:/数据集/UNSW_NB15/UNSW_NB15_CSV/UNSW_NB15_testing-set.csv\"\n",
    "df_train=pd.read_csv(path_train, header=0,dtype='unicode')\n",
    "df_test=pd.read_csv(path_test, header=0,dtype='unicode')\n",
    "columns_full = df_train.columns.tolist()\n",
    "\n",
    "x_train = df_train.iloc[:,:-1]\n",
    "x_test = df_test.iloc[:,:-1]\n",
    "columns = x_train.columns.tolist()\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide training data to 1 or 0\n",
    "df_class_Normal = df_train[df_train['label'] == '0']\n",
    "df_class_Attack = df_train[df_train['label'] == '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define MinMaxScaler normalize\n",
    "def numerical_minmax_normalization (df, name):\n",
    "    x = df[name].values.reshape(-1,1)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df[name] = x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_normal, x_test_normal = train_test_split(df_class_Normal, test_size=0.2, random_state=920)\n",
    "x_train_attack, x_test_attack = train_test_split(df_class_Attack, test_size=0.2, random_state=920)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_normal = x_train_normal.drop(['label'], axis=1)\n",
    "x_test_normal = x_test_normal.drop(['label'], axis=1)\n",
    "x_train_attack = x_train_attack.drop(['label'], axis=1)\n",
    "x_test_attack = x_test_attack.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(columns)):\n",
    "    numerical_minmax_normalization(x_train_normal,columns[i])\n",
    "    numerical_minmax_normalization(x_train_attack,columns[i])\n",
    "    numerical_minmax_normalization(x_test_attack,columns[i])\n",
    "    numerical_minmax_normalization(x_test_normal,columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the number of normal and attack\n",
    "num_Normal = len(df_class_Normal)\n",
    "num_Attack = len(df_class_Attack)\n",
    "plt.bar(['Normal', 'Attack'], [num_Normal, num_Attack], color='dodgerblue')\n",
    "plt.show()\n",
    "\n",
    "x_train_attack_len = len(x_train_attack)\n",
    "x_train_normal_len = len(x_train_normal)\n",
    "x_test_attack_len = len(x_test_attack)\n",
    "x_test_normal_len = len(x_test_normal)\n",
    "\n",
    "plt.bar(['x_train_attack', 'x_train_normal', 'x_test_attack', 'x_test_normal'], [x_train_attack_len, x_train_normal_len, x_test_attack_len, x_test_normal_len], color='dodgerblue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_test.drop(['label'], axis=1)\n",
    "\n",
    "for i in range(len(columns)):\n",
    "    numerical_minmax_normalization(test,columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal-AE\n",
    "input_img = keras.Input(shape=(42,))\n",
    "encoded = keras.layers.Dense(30, activation='relu',activity_regularizer=keras.regularizers.l1(10e-5))(input_img)\n",
    "encoded = keras.layers.Dense(20, activation='relu')(encoded)\n",
    "\n",
    "decoded = keras.layers.Dense(30, activation='relu')(encoded)\n",
    "decoded = keras.layers.Dense(42, activation='relu')(decoded)\n",
    "\n",
    "autoencoder_normal = keras.Model(input_img, decoded)\n",
    "\n",
    "autoencoder_normal.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "autoencoder_normal.fit(x_train_normal, x_train_normal,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_normal, x_test_normal))\n",
    "\n",
    "nor = autoencoder_normal.predict(test)\n",
    "nor = pd.DataFrame(nor, columns=columns)\n",
    "print(nor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attack-AE\n",
    "input_img = keras.Input(shape=(42,))\n",
    "encoded = keras.layers.Dense(30, activation='relu',activity_regularizer=keras.regularizers.l1(10e-5))(input_img)\n",
    "encoded = keras.layers.Dense(20, activation='relu')(encoded)\n",
    "\n",
    "decoded = keras.layers.Dense(30, activation='relu')(encoded)\n",
    "decoded = keras.layers.Dense(42, activation='relu')(decoded)\n",
    "\n",
    "autoencoder_attack = keras.Model(input_img, decoded)\n",
    "\n",
    "autoencoder_attack.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "\n",
    "autoencoder_attack.fit(x_train_attack, x_train_attack,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_attack, x_test_attack))\n",
    "\n",
    "att = autoencoder_attack.predict(test)\n",
    "att = pd.DataFrame(att, columns=columns)\n",
    "print(att)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine sample of AE with testing_set\n",
    "df_normal = (nor+test)/2\n",
    "df_normal = pd.DataFrame(df_normal, columns=columns_full)\n",
    "df_normal['label'] = df_test['label']\n",
    "df_normal.to_csv(\"F:/数据集/UNSW_NB15/UNSW_NB15_CSV/test_nor.csv\", index=0)\n",
    "\n",
    "df_attack = (att+test)/2\n",
    "df_attack = pd.DataFrame(df_attack, columns=columns_full)\n",
    "df_attack['label'] = df_test['label']\n",
    "df_attack.to_csv(\"F:/数据集/UNSW_NB15/UNSW_NB15_CSV/test_att.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.robjects as robjects\n",
    "#train AddTree\n",
    "robjects.r('library(rtemis)')\n",
    "\n",
    "#normal\n",
    "robjects.r('normal <- read.csv(\"F:/数据集/UNSW_NB15/UNSW_NB15_CSV/test_nor.csv\")')\n",
    "robjects.r('normal$Label <- factor(normal$label, levels = c(1,0))')\n",
    "robjects.r('normal$label <- NULL')\n",
    "robjects.r('res <- resample(normal, n.resamples = 3, resampler = \"kfold\", verbose = TRUE)')\n",
    "robjects.r('normal.train <- normal[res$Fold_1, ]')\n",
    "robjects.r('normal.test <- normal[-res$Fold_1, ]')\n",
    "robjects.r('normal.addtree <- s.ADDTREE(normal.train, x.test = normal.test, gamma=.9,learning.rate=.01)')\n",
    "normal_mat = robjects.r('normal.addtree$error.test$Overall')\n",
    "#attack\n",
    "robjects.r('attack <- read.csv(\"F:/数据集/UNSW_NB15/UNSW_NB15_CSV/test_att.csv\")')\n",
    "robjects.r('attack$Label <- factor(attack$label, levels = c(1,0))')\n",
    "robjects.r('attack$label <- NULL')\n",
    "robjects.r('res <- resample(attack, n.resamples = 3, resampler = \"kfold\", verbose = TRUE)')\n",
    "robjects.r('attack.train <- attack[res$Fold_1, ]')\n",
    "robjects.r('attack.test <- attack[-res$Fold_1, ]')\n",
    "robjects.r('attack.addtree <- s.ADDTREE(attack.train, x.test = attack.test, gamma=.9,learning.rate=.01)')\n",
    "attack_mat = robjects.r('attack.addtree$error.test$Overall')\n",
    "\n",
    "print(normal_mat)\n",
    "print(attack_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the tree\n",
    "img_normal = robjects.r('dplot3.addtree(normal.addtree)')\n",
    "print(img_normal)\n",
    "img_attack = robjects.r('dplot3.addtree(attack.addtree)')\n",
    "print(img_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "def voting_machine():\n",
    "    #data\n",
    "    #df = pd.read_csv('F:/数据集/UNSW_NB15/UNSW_NB15_CSV/nn.csv', header=0)\n",
    "    train_data = df.iloc[:,:2]\n",
    "    train_target = df.iloc[:,2]\n",
    "    \n",
    "    #for i in range(len(train_target)):\n",
    "    #    train_target[i] = train_target[i]-1\n",
    "    x_train, x_test, y_train, y_test = train_test_split(train_data, train_target, test_size=0.4, random_state=0)\n",
    "    y_train = keras.utils.to_categorical(y_train,2)\n",
    "    y_test = keras.utils.to_categorical(y_test,2)\n",
    "    #model\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(4,activation='relu',input_shape=(2,), name=\"Dense_1\"))\n",
    "    model.add(keras.layers.Dropout(0.001))\n",
    "    model.add(keras.layers.Dense(2, activation='softmax', name=\"Dense_2\"))\n",
    "    model.summary()\n",
    "    model.compile(optimizer=keras.optimizers.Adam(),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, batch_size=64, epochs=50, validation_data=(x_test,y_test))\n",
    "    \n",
    "    pre_l = []\n",
    "    y_test_l = []\n",
    "    pre = model.predict(x_test)\n",
    "    \n",
    "    \n",
    "    for i in range(len(pre)):\n",
    "        pre_l.append(list(pre[i]).index(max(list(pre[i]), key = abs)))\n",
    "        y_test_l.append(list(y_test[i]).index(max(list(y_test[i]), key = abs)))\n",
    "    \n",
    "    print(\"accuracy is %.4f\"%accuracy_score(y_test_l, pre_l))\n",
    "    print(\"precision is %.4f\"%precision_score(y_test_l, pre_l))\n",
    "    print(\"recall is %.4f\"%recall_score(y_test_l, pre_l))\n",
    "    print(\"f1_score is %.4f\"%f1_score(y_test_l, pre_l))\n",
    "    \"\"\"\n",
    "    score = model.evaluate(x_test, y_test)\n",
    "    print(\"loss:\",score[0])\n",
    "    print(\"accu:\",score[1])\n",
    "    \n",
    "    weight_Dense_1,bias_Dense_1 = model.get_layer('Dense_1').get_weights()\n",
    "    print(weight_Dense_1.round(4))\n",
    "    print(bias_Dense_1.round(4))\n",
    "    print('---------------------------------------------')\n",
    "    weight_Dense_2,bias_Dense_2 = model.get_layer('Dense_2').get_weights()\n",
    "    print(weight_Dense_2.round(4))\n",
    "    print(bias_Dense_2.round(4))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_pre = robjects.r('predict(normal.addtree, test)')\n",
    "attack_pre = robjects.r('predict(attack.addtree, test)')\n",
    "df = pd.DataFrame(columns=[normal,attack,label])\n",
    "df['normal'] = normal_pre\n",
    "df['attack'] = attack_pre\n",
    "df['label'] = df_test['label']\n",
    "voting_machine(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
